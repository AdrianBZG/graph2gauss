{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from g2g.model import Graph2Gauss\n",
    "from g2g.utils import load_dataset, score_link_prediction, score_node_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = load_dataset('data/cora_ml.npz')\n",
    "A, X, z = g['A'], g['X'], g['z']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model and evaluate the link prediction performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   0, loss: 0.9582, val_auc: 0.6815, val_ap: 0.7130\n",
      "epoch:   1, loss: 0.9476, val_auc: 0.7038, val_ap: 0.7338\n",
      "epoch:   2, loss: 0.9342, val_auc: 0.7206, val_ap: 0.7489\n",
      "epoch:   3, loss: 0.9185, val_auc: 0.7350, val_ap: 0.7613\n",
      "epoch:   4, loss: 0.9004, val_auc: 0.7477, val_ap: 0.7730\n",
      "epoch:   5, loss: 0.8791, val_auc: 0.7582, val_ap: 0.7822\n",
      "epoch:   6, loss: 0.8544, val_auc: 0.7686, val_ap: 0.7905\n",
      "epoch:   7, loss: 0.8266, val_auc: 0.7799, val_ap: 0.7990\n",
      "epoch:   8, loss: 0.8004, val_auc: 0.7919, val_ap: 0.8080\n",
      "epoch:   9, loss: 0.7678, val_auc: 0.8058, val_ap: 0.8180\n",
      "epoch:  10, loss: 0.7351, val_auc: 0.8201, val_ap: 0.8284\n",
      "epoch:  11, loss: 0.7078, val_auc: 0.8338, val_ap: 0.8394\n",
      "epoch:  12, loss: 0.6816, val_auc: 0.8471, val_ap: 0.8507\n",
      "epoch:  13, loss: 0.6581, val_auc: 0.8590, val_ap: 0.8614\n",
      "epoch:  14, loss: 0.6349, val_auc: 0.8702, val_ap: 0.8717\n",
      "epoch:  15, loss: 0.6239, val_auc: 0.8802, val_ap: 0.8809\n",
      "epoch:  16, loss: 0.6009, val_auc: 0.8894, val_ap: 0.8895\n",
      "epoch:  17, loss: 0.5791, val_auc: 0.8980, val_ap: 0.8972\n",
      "epoch:  18, loss: 0.5601, val_auc: 0.9056, val_ap: 0.9039\n",
      "epoch:  19, loss: 0.5323, val_auc: 0.9120, val_ap: 0.9094\n",
      "epoch:  20, loss: 0.5188, val_auc: 0.9179, val_ap: 0.9145\n",
      "epoch:  21, loss: 0.4996, val_auc: 0.9230, val_ap: 0.9190\n",
      "epoch:  22, loss: 0.4759, val_auc: 0.9273, val_ap: 0.9228\n",
      "epoch:  23, loss: 0.4646, val_auc: 0.9311, val_ap: 0.9263\n",
      "epoch:  24, loss: 0.4499, val_auc: 0.9339, val_ap: 0.9289\n",
      "epoch:  25, loss: 0.4358, val_auc: 0.9364, val_ap: 0.9315\n",
      "epoch:  26, loss: 0.4247, val_auc: 0.9386, val_ap: 0.9335\n",
      "epoch:  27, loss: 0.4105, val_auc: 0.9402, val_ap: 0.9352\n",
      "epoch:  28, loss: 0.4039, val_auc: 0.9419, val_ap: 0.9368\n",
      "epoch:  29, loss: 0.3857, val_auc: 0.9432, val_ap: 0.9380\n",
      "epoch:  30, loss: 0.3866, val_auc: 0.9445, val_ap: 0.9391\n",
      "epoch:  31, loss: 0.3742, val_auc: 0.9456, val_ap: 0.9401\n",
      "epoch:  32, loss: 0.3632, val_auc: 0.9468, val_ap: 0.9412\n",
      "epoch:  33, loss: 0.3636, val_auc: 0.9480, val_ap: 0.9424\n",
      "epoch:  34, loss: 0.3418, val_auc: 0.9491, val_ap: 0.9436\n",
      "epoch:  35, loss: 0.3312, val_auc: 0.9502, val_ap: 0.9448\n",
      "epoch:  36, loss: 0.3309, val_auc: 0.9512, val_ap: 0.9459\n",
      "epoch:  37, loss: 0.3209, val_auc: 0.9521, val_ap: 0.9467\n",
      "epoch:  38, loss: 0.3046, val_auc: 0.9529, val_ap: 0.9477\n",
      "epoch:  39, loss: 0.3009, val_auc: 0.9536, val_ap: 0.9486\n",
      "epoch:  40, loss: 0.2988, val_auc: 0.9543, val_ap: 0.9494\n",
      "epoch:  41, loss: 0.2966, val_auc: 0.9550, val_ap: 0.9500\n",
      "epoch:  42, loss: 0.2806, val_auc: 0.9556, val_ap: 0.9507\n",
      "epoch:  43, loss: 0.2890, val_auc: 0.9562, val_ap: 0.9512\n",
      "epoch:  44, loss: 0.2725, val_auc: 0.9568, val_ap: 0.9518\n",
      "epoch:  45, loss: 0.2686, val_auc: 0.9573, val_ap: 0.9523\n",
      "epoch:  46, loss: 0.2682, val_auc: 0.9577, val_ap: 0.9525\n",
      "epoch:  47, loss: 0.2548, val_auc: 0.9579, val_ap: 0.9529\n",
      "epoch:  48, loss: 0.2569, val_auc: 0.9584, val_ap: 0.9536\n",
      "epoch:  49, loss: 0.2521, val_auc: 0.9590, val_ap: 0.9544\n",
      "epoch:  50, loss: 0.2497, val_auc: 0.9594, val_ap: 0.9549\n",
      "epoch:  51, loss: 0.2514, val_auc: 0.9597, val_ap: 0.9554\n",
      "epoch:  52, loss: 0.2457, val_auc: 0.9599, val_ap: 0.9558\n",
      "epoch:  53, loss: 0.2367, val_auc: 0.9601, val_ap: 0.9560\n",
      "epoch:  54, loss: 0.2387, val_auc: 0.9602, val_ap: 0.9561\n",
      "epoch:  55, loss: 0.2349, val_auc: 0.9603, val_ap: 0.9562\n",
      "epoch:  56, loss: 0.2320, val_auc: 0.9605, val_ap: 0.9566\n",
      "epoch:  57, loss: 0.2234, val_auc: 0.9608, val_ap: 0.9570\n",
      "epoch:  58, loss: 0.2190, val_auc: 0.9611, val_ap: 0.9575\n",
      "epoch:  59, loss: 0.2143, val_auc: 0.9613, val_ap: 0.9579\n",
      "epoch:  60, loss: 0.2147, val_auc: 0.9615, val_ap: 0.9581\n",
      "epoch:  61, loss: 0.2095, val_auc: 0.9617, val_ap: 0.9584\n",
      "epoch:  62, loss: 0.2131, val_auc: 0.9618, val_ap: 0.9587\n",
      "epoch:  63, loss: 0.2058, val_auc: 0.9619, val_ap: 0.9590\n",
      "epoch:  64, loss: 0.2097, val_auc: 0.9621, val_ap: 0.9592\n",
      "epoch:  65, loss: 0.2011, val_auc: 0.9622, val_ap: 0.9593\n",
      "epoch:  66, loss: 0.1996, val_auc: 0.9623, val_ap: 0.9594\n",
      "epoch:  67, loss: 0.1955, val_auc: 0.9622, val_ap: 0.9592\n",
      "epoch:  68, loss: 0.1973, val_auc: 0.9623, val_ap: 0.9592\n",
      "epoch:  69, loss: 0.2006, val_auc: 0.9624, val_ap: 0.9591\n",
      "epoch:  70, loss: 0.1927, val_auc: 0.9625, val_ap: 0.9591\n",
      "epoch:  71, loss: 0.1913, val_auc: 0.9627, val_ap: 0.9593\n",
      "epoch:  72, loss: 0.1890, val_auc: 0.9628, val_ap: 0.9594\n",
      "epoch:  73, loss: 0.1841, val_auc: 0.9628, val_ap: 0.9594\n",
      "epoch:  74, loss: 0.1852, val_auc: 0.9628, val_ap: 0.9595\n",
      "epoch:  75, loss: 0.1896, val_auc: 0.9629, val_ap: 0.9597\n",
      "epoch:  76, loss: 0.1806, val_auc: 0.9628, val_ap: 0.9598\n",
      "epoch:  77, loss: 0.1806, val_auc: 0.9627, val_ap: 0.9598\n",
      "epoch:  78, loss: 0.1786, val_auc: 0.9626, val_ap: 0.9598\n",
      "epoch:  79, loss: 0.1756, val_auc: 0.9624, val_ap: 0.9598\n",
      "epoch:  80, loss: 0.1819, val_auc: 0.9623, val_ap: 0.9598\n",
      "epoch:  81, loss: 0.1793, val_auc: 0.9623, val_ap: 0.9599\n",
      "epoch:  82, loss: 0.1709, val_auc: 0.9621, val_ap: 0.9599\n",
      "epoch:  83, loss: 0.1702, val_auc: 0.9620, val_ap: 0.9598\n",
      "epoch:  84, loss: 0.1656, val_auc: 0.9619, val_ap: 0.9599\n",
      "epoch:  85, loss: 0.1722, val_auc: 0.9620, val_ap: 0.9599\n",
      "epoch:  86, loss: 0.1683, val_auc: 0.9619, val_ap: 0.9598\n",
      "epoch:  87, loss: 0.1663, val_auc: 0.9617, val_ap: 0.9595\n",
      "epoch:  88, loss: 0.1657, val_auc: 0.9618, val_ap: 0.9595\n",
      "epoch:  89, loss: 0.1639, val_auc: 0.9617, val_ap: 0.9596\n",
      "epoch:  90, loss: 0.1670, val_auc: 0.9616, val_ap: 0.9594\n",
      "epoch:  91, loss: 0.1659, val_auc: 0.9616, val_ap: 0.9593\n",
      "epoch:  92, loss: 0.1654, val_auc: 0.9615, val_ap: 0.9590\n",
      "epoch:  93, loss: 0.1624, val_auc: 0.9614, val_ap: 0.9588\n",
      "epoch:  94, loss: 0.1645, val_auc: 0.9612, val_ap: 0.9584\n",
      "epoch:  95, loss: 0.1619, val_auc: 0.9611, val_ap: 0.9581\n",
      "epoch:  96, loss: 0.1611, val_auc: 0.9607, val_ap: 0.9576\n",
      "epoch:  97, loss: 0.1613, val_auc: 0.9602, val_ap: 0.9568\n",
      "epoch:  98, loss: 0.1610, val_auc: 0.9599, val_ap: 0.9561\n",
      "epoch:  99, loss: 0.1615, val_auc: 0.9597, val_ap: 0.9555\n",
      "epoch: 100, loss: 0.1631, val_auc: 0.9598, val_ap: 0.9554\n",
      "epoch: 101, loss: 0.1550, val_auc: 0.9601, val_ap: 0.9554\n",
      "epoch: 102, loss: 0.1612, val_auc: 0.9604, val_ap: 0.9556\n",
      "epoch: 103, loss: 0.1535, val_auc: 0.9607, val_ap: 0.9557\n",
      "epoch: 104, loss: 0.1610, val_auc: 0.9610, val_ap: 0.9561\n",
      "epoch: 105, loss: 0.1508, val_auc: 0.9612, val_ap: 0.9562\n",
      "epoch: 106, loss: 0.1555, val_auc: 0.9614, val_ap: 0.9566\n",
      "epoch: 107, loss: 0.1529, val_auc: 0.9615, val_ap: 0.9569\n",
      "epoch: 108, loss: 0.1553, val_auc: 0.9617, val_ap: 0.9575\n",
      "epoch: 109, loss: 0.1532, val_auc: 0.9618, val_ap: 0.9580\n",
      "epoch: 110, loss: 0.1500, val_auc: 0.9621, val_ap: 0.9586\n",
      "epoch: 111, loss: 0.1523, val_auc: 0.9624, val_ap: 0.9594\n",
      "epoch: 112, loss: 0.1490, val_auc: 0.9627, val_ap: 0.9601\n",
      "epoch: 113, loss: 0.1471, val_auc: 0.9630, val_ap: 0.9607\n",
      "epoch: 114, loss: 0.1428, val_auc: 0.9634, val_ap: 0.9616\n",
      "epoch: 115, loss: 0.1442, val_auc: 0.9635, val_ap: 0.9620\n",
      "epoch: 116, loss: 0.1451, val_auc: 0.9636, val_ap: 0.9622\n",
      "epoch: 117, loss: 0.1559, val_auc: 0.9637, val_ap: 0.9623\n",
      "epoch: 118, loss: 0.1510, val_auc: 0.9638, val_ap: 0.9624\n",
      "epoch: 119, loss: 0.1443, val_auc: 0.9638, val_ap: 0.9622\n",
      "epoch: 120, loss: 0.1529, val_auc: 0.9639, val_ap: 0.9621\n",
      "epoch: 121, loss: 0.1434, val_auc: 0.9639, val_ap: 0.9619\n",
      "epoch: 122, loss: 0.1379, val_auc: 0.9640, val_ap: 0.9617\n",
      "epoch: 123, loss: 0.1486, val_auc: 0.9639, val_ap: 0.9614\n",
      "epoch: 124, loss: 0.1399, val_auc: 0.9637, val_ap: 0.9610\n",
      "epoch: 125, loss: 0.1472, val_auc: 0.9636, val_ap: 0.9607\n",
      "epoch: 126, loss: 0.1459, val_auc: 0.9634, val_ap: 0.9603\n",
      "epoch: 127, loss: 0.1413, val_auc: 0.9632, val_ap: 0.9598\n",
      "epoch: 128, loss: 0.1380, val_auc: 0.9630, val_ap: 0.9595\n",
      "epoch: 129, loss: 0.1395, val_auc: 0.9627, val_ap: 0.9590\n",
      "epoch: 130, loss: 0.1391, val_auc: 0.9625, val_ap: 0.9587\n",
      "epoch: 131, loss: 0.1429, val_auc: 0.9623, val_ap: 0.9582\n",
      "epoch: 132, loss: 0.1358, val_auc: 0.9621, val_ap: 0.9578\n",
      "epoch: 133, loss: 0.1369, val_auc: 0.9620, val_ap: 0.9575\n",
      "epoch: 134, loss: 0.1385, val_auc: 0.9621, val_ap: 0.9574\n",
      "epoch: 135, loss: 0.1411, val_auc: 0.9623, val_ap: 0.9575\n",
      "epoch: 136, loss: 0.1432, val_auc: 0.9625, val_ap: 0.9577\n",
      "epoch: 137, loss: 0.1395, val_auc: 0.9627, val_ap: 0.9580\n",
      "epoch: 138, loss: 0.1323, val_auc: 0.9628, val_ap: 0.9580\n",
      "epoch: 139, loss: 0.1427, val_auc: 0.9628, val_ap: 0.9581\n",
      "epoch: 140, loss: 0.1366, val_auc: 0.9627, val_ap: 0.9579\n",
      "epoch: 141, loss: 0.1369, val_auc: 0.9626, val_ap: 0.9579\n",
      "epoch: 142, loss: 0.1406, val_auc: 0.9626, val_ap: 0.9581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 143, loss: 0.1374, val_auc: 0.9626, val_ap: 0.9584\n",
      "epoch: 144, loss: 0.1338, val_auc: 0.9625, val_ap: 0.9586\n",
      "epoch: 145, loss: 0.1374, val_auc: 0.9626, val_ap: 0.9590\n",
      "epoch: 146, loss: 0.1361, val_auc: 0.9626, val_ap: 0.9593\n",
      "epoch: 147, loss: 0.1428, val_auc: 0.9627, val_ap: 0.9597\n",
      "epoch: 148, loss: 0.1385, val_auc: 0.9626, val_ap: 0.9599\n",
      "epoch: 149, loss: 0.1399, val_auc: 0.9626, val_ap: 0.9601\n",
      "epoch: 150, loss: 0.1366, val_auc: 0.9625, val_ap: 0.9601\n",
      "epoch: 151, loss: 0.1344, val_auc: 0.9622, val_ap: 0.9599\n",
      "epoch: 152, loss: 0.1352, val_auc: 0.9620, val_ap: 0.9597\n",
      "epoch: 153, loss: 0.1395, val_auc: 0.9618, val_ap: 0.9593\n",
      "epoch: 154, loss: 0.1343, val_auc: 0.9615, val_ap: 0.9587\n",
      "epoch: 155, loss: 0.1353, val_auc: 0.9614, val_ap: 0.9584\n",
      "epoch: 156, loss: 0.1327, val_auc: 0.9614, val_ap: 0.9582\n",
      "epoch: 157, loss: 0.1410, val_auc: 0.9614, val_ap: 0.9583\n",
      "epoch: 158, loss: 0.1354, val_auc: 0.9614, val_ap: 0.9582\n",
      "epoch: 159, loss: 0.1371, val_auc: 0.9614, val_ap: 0.9581\n",
      "epoch: 160, loss: 0.1295, val_auc: 0.9615, val_ap: 0.9581\n",
      "epoch: 161, loss: 0.1289, val_auc: 0.9616, val_ap: 0.9581\n",
      "epoch: 162, loss: 0.1326, val_auc: 0.9618, val_ap: 0.9583\n",
      "epoch: 163, loss: 0.1367, val_auc: 0.9620, val_ap: 0.9584\n",
      "epoch: 164, loss: 0.1317, val_auc: 0.9620, val_ap: 0.9584\n",
      "epoch: 165, loss: 0.1427, val_auc: 0.9620, val_ap: 0.9584\n",
      "epoch: 166, loss: 0.1253, val_auc: 0.9621, val_ap: 0.9585\n",
      "epoch: 167, loss: 0.1338, val_auc: 0.9620, val_ap: 0.9583\n",
      "epoch: 168, loss: 0.1318, val_auc: 0.9620, val_ap: 0.9584\n",
      "epoch: 169, loss: 0.1311, val_auc: 0.9620, val_ap: 0.9584\n",
      "epoch: 170, loss: 0.1324, val_auc: 0.9620, val_ap: 0.9584\n",
      "epoch: 171, loss: 0.1303, val_auc: 0.9619, val_ap: 0.9585\n",
      "epoch: 172, loss: 0.1371, val_auc: 0.9619, val_ap: 0.9585\n",
      "epoch: 173, loss: 0.1300, val_auc: 0.9620, val_ap: 0.9589\n",
      "epoch: 174, loss: 0.1305, val_auc: 0.9620, val_ap: 0.9590\n",
      "epoch: 175, loss: 0.1352, val_auc: 0.9620, val_ap: 0.9591\n",
      "epoch: 176, loss: 0.1311, val_auc: 0.9621, val_ap: 0.9593\n",
      "epoch: 177, loss: 0.1292, val_auc: 0.9622, val_ap: 0.9595\n",
      "epoch: 178, loss: 0.1320, val_auc: 0.9623, val_ap: 0.9597\n",
      "epoch: 179, loss: 0.1273, val_auc: 0.9624, val_ap: 0.9599\n",
      "epoch: 180, loss: 0.1227, val_auc: 0.9625, val_ap: 0.9601\n",
      "epoch: 181, loss: 0.1273, val_auc: 0.9625, val_ap: 0.9602\n",
      "epoch: 182, loss: 0.1248, val_auc: 0.9625, val_ap: 0.9603\n",
      "epoch: 183, loss: 0.1320, val_auc: 0.9624, val_ap: 0.9603\n",
      "epoch: 184, loss: 0.1279, val_auc: 0.9624, val_ap: 0.9602\n",
      "epoch: 185, loss: 0.1310, val_auc: 0.9622, val_ap: 0.9601\n",
      "epoch: 186, loss: 0.1278, val_auc: 0.9622, val_ap: 0.9599\n",
      "epoch: 187, loss: 0.1247, val_auc: 0.9621, val_ap: 0.9598\n",
      "epoch: 188, loss: 0.1258, val_auc: 0.9623, val_ap: 0.9599\n",
      "epoch: 189, loss: 0.1273, val_auc: 0.9624, val_ap: 0.9598\n",
      "epoch: 190, loss: 0.1333, val_auc: 0.9626, val_ap: 0.9599\n",
      "epoch: 191, loss: 0.1230, val_auc: 0.9627, val_ap: 0.9601\n",
      "epoch: 192, loss: 0.1239, val_auc: 0.9627, val_ap: 0.9601\n",
      "epoch: 193, loss: 0.1272, val_auc: 0.9629, val_ap: 0.9605\n",
      "epoch: 194, loss: 0.1285, val_auc: 0.9630, val_ap: 0.9608\n",
      "epoch: 195, loss: 0.1224, val_auc: 0.9631, val_ap: 0.9612\n",
      "epoch: 196, loss: 0.1331, val_auc: 0.9630, val_ap: 0.9612\n",
      "epoch: 197, loss: 0.1282, val_auc: 0.9630, val_ap: 0.9614\n",
      "epoch: 198, loss: 0.1342, val_auc: 0.9629, val_ap: 0.9613\n",
      "epoch: 199, loss: 0.1239, val_auc: 0.9628, val_ap: 0.9611\n",
      "epoch: 200, loss: 0.1194, val_auc: 0.9626, val_ap: 0.9608\n",
      "epoch: 201, loss: 0.1317, val_auc: 0.9625, val_ap: 0.9608\n",
      "epoch: 202, loss: 0.1261, val_auc: 0.9624, val_ap: 0.9607\n",
      "epoch: 203, loss: 0.1220, val_auc: 0.9623, val_ap: 0.9606\n",
      "epoch: 204, loss: 0.1275, val_auc: 0.9622, val_ap: 0.9606\n",
      "epoch: 205, loss: 0.1172, val_auc: 0.9620, val_ap: 0.9605\n",
      "epoch: 206, loss: 0.1267, val_auc: 0.9620, val_ap: 0.9606\n",
      "epoch: 207, loss: 0.1252, val_auc: 0.9619, val_ap: 0.9605\n",
      "epoch: 208, loss: 0.1159, val_auc: 0.9619, val_ap: 0.9606\n",
      "epoch: 209, loss: 0.1277, val_auc: 0.9619, val_ap: 0.9607\n",
      "epoch: 210, loss: 0.1197, val_auc: 0.9621, val_ap: 0.9608\n",
      "epoch: 211, loss: 0.1274, val_auc: 0.9622, val_ap: 0.9610\n",
      "epoch: 212, loss: 0.1296, val_auc: 0.9623, val_ap: 0.9611\n",
      "epoch: 213, loss: 0.1285, val_auc: 0.9625, val_ap: 0.9611\n",
      "epoch: 214, loss: 0.1190, val_auc: 0.9627, val_ap: 0.9613\n",
      "epoch: 215, loss: 0.1215, val_auc: 0.9629, val_ap: 0.9613\n",
      "epoch: 216, loss: 0.1291, val_auc: 0.9630, val_ap: 0.9613\n",
      "epoch: 217, loss: 0.1220, val_auc: 0.9631, val_ap: 0.9612\n",
      "epoch: 218, loss: 0.1286, val_auc: 0.9631, val_ap: 0.9612\n"
     ]
    }
   ],
   "source": [
    "g2g = Graph2Gauss(A=A, X=X, L=64, verbose=True, p_val=0.10, p_test=0.05)\n",
    "sess = g2g.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_auc: 0.9753, test_ap: 0.9766\n"
     ]
    }
   ],
   "source": [
    "test_auc, test_ap = score_link_prediction(g2g.test_ground_truth, sess.run(g2g.neg_test_energy))\n",
    "print('test_auc: {:.4f}, test_ap: {:.4f}'.format(test_auc, test_ap))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train another model and evaluate the node classification performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   0, loss: 0.9583\n",
      "epoch:   1, loss: 0.9475\n",
      "epoch:   2, loss: 0.9344\n",
      "epoch:   3, loss: 0.9185\n",
      "epoch:   4, loss: 0.9000\n",
      "epoch:   5, loss: 0.8790\n",
      "epoch:   6, loss: 0.8558\n",
      "epoch:   7, loss: 0.8286\n",
      "epoch:   8, loss: 0.8006\n",
      "epoch:   9, loss: 0.7678\n",
      "epoch:  10, loss: 0.7375\n",
      "epoch:  11, loss: 0.7084\n",
      "epoch:  12, loss: 0.6857\n",
      "epoch:  13, loss: 0.6578\n",
      "epoch:  14, loss: 0.6365\n",
      "epoch:  15, loss: 0.6174\n",
      "epoch:  16, loss: 0.5953\n",
      "epoch:  17, loss: 0.5791\n",
      "epoch:  18, loss: 0.5575\n",
      "epoch:  19, loss: 0.5321\n",
      "epoch:  20, loss: 0.5220\n",
      "epoch:  21, loss: 0.5020\n",
      "epoch:  22, loss: 0.4838\n",
      "epoch:  23, loss: 0.4708\n",
      "epoch:  24, loss: 0.4482\n",
      "epoch:  25, loss: 0.4428\n",
      "epoch:  26, loss: 0.4302\n",
      "epoch:  27, loss: 0.4170\n",
      "epoch:  28, loss: 0.4010\n",
      "epoch:  29, loss: 0.3952\n",
      "epoch:  30, loss: 0.3818\n",
      "epoch:  31, loss: 0.3736\n",
      "epoch:  32, loss: 0.3593\n",
      "epoch:  33, loss: 0.3496\n",
      "epoch:  34, loss: 0.3548\n",
      "epoch:  35, loss: 0.3410\n",
      "epoch:  36, loss: 0.3393\n",
      "epoch:  37, loss: 0.3257\n",
      "epoch:  38, loss: 0.3047\n",
      "epoch:  39, loss: 0.3119\n",
      "epoch:  40, loss: 0.3069\n",
      "epoch:  41, loss: 0.2950\n",
      "epoch:  42, loss: 0.2966\n",
      "epoch:  43, loss: 0.2861\n",
      "epoch:  44, loss: 0.2772\n",
      "epoch:  45, loss: 0.2827\n",
      "epoch:  46, loss: 0.2734\n",
      "epoch:  47, loss: 0.2626\n",
      "epoch:  48, loss: 0.2685\n",
      "epoch:  49, loss: 0.2652\n",
      "epoch:  50, loss: 0.2612\n",
      "epoch:  51, loss: 0.2573\n",
      "epoch:  52, loss: 0.2442\n",
      "epoch:  53, loss: 0.2382\n",
      "epoch:  54, loss: 0.2417\n",
      "epoch:  55, loss: 0.2402\n",
      "epoch:  56, loss: 0.2409\n",
      "epoch:  57, loss: 0.2328\n",
      "epoch:  58, loss: 0.2297\n",
      "epoch:  59, loss: 0.2271\n",
      "epoch:  60, loss: 0.2250\n",
      "epoch:  61, loss: 0.2102\n",
      "epoch:  62, loss: 0.2223\n",
      "epoch:  63, loss: 0.2098\n",
      "epoch:  64, loss: 0.2145\n",
      "epoch:  65, loss: 0.2134\n",
      "epoch:  66, loss: 0.2086\n",
      "epoch:  67, loss: 0.2112\n",
      "epoch:  68, loss: 0.2019\n",
      "epoch:  69, loss: 0.2029\n",
      "epoch:  70, loss: 0.2027\n",
      "epoch:  71, loss: 0.1939\n",
      "epoch:  72, loss: 0.1950\n",
      "epoch:  73, loss: 0.2029\n",
      "epoch:  74, loss: 0.2012\n",
      "epoch:  75, loss: 0.1907\n",
      "epoch:  76, loss: 0.1924\n",
      "epoch:  77, loss: 0.1832\n",
      "epoch:  78, loss: 0.1891\n",
      "epoch:  79, loss: 0.1834\n",
      "epoch:  80, loss: 0.1867\n",
      "epoch:  81, loss: 0.1881\n",
      "epoch:  82, loss: 0.1900\n",
      "epoch:  83, loss: 0.1818\n",
      "epoch:  84, loss: 0.1789\n",
      "epoch:  85, loss: 0.1770\n",
      "epoch:  86, loss: 0.1896\n",
      "epoch:  87, loss: 0.1780\n",
      "epoch:  88, loss: 0.1738\n",
      "epoch:  89, loss: 0.1788\n",
      "epoch:  90, loss: 0.1801\n",
      "epoch:  91, loss: 0.1730\n",
      "epoch:  92, loss: 0.1753\n",
      "epoch:  93, loss: 0.1738\n",
      "epoch:  94, loss: 0.1718\n",
      "epoch:  95, loss: 0.1748\n",
      "epoch:  96, loss: 0.1718\n",
      "epoch:  97, loss: 0.1711\n",
      "epoch:  98, loss: 0.1698\n",
      "epoch:  99, loss: 0.1682\n",
      "epoch: 100, loss: 0.1691\n",
      "epoch: 101, loss: 0.1682\n",
      "epoch: 102, loss: 0.1665\n",
      "epoch: 103, loss: 0.1646\n",
      "epoch: 104, loss: 0.1651\n",
      "epoch: 105, loss: 0.1669\n",
      "epoch: 106, loss: 0.1660\n",
      "epoch: 107, loss: 0.1657\n",
      "epoch: 108, loss: 0.1657\n",
      "epoch: 109, loss: 0.1678\n",
      "epoch: 110, loss: 0.1628\n",
      "epoch: 111, loss: 0.1646\n",
      "epoch: 112, loss: 0.1631\n",
      "epoch: 113, loss: 0.1625\n",
      "epoch: 114, loss: 0.1611\n",
      "epoch: 115, loss: 0.1657\n",
      "epoch: 116, loss: 0.1596\n",
      "epoch: 117, loss: 0.1575\n",
      "epoch: 118, loss: 0.1631\n",
      "epoch: 119, loss: 0.1555\n",
      "epoch: 120, loss: 0.1582\n",
      "epoch: 121, loss: 0.1546\n",
      "epoch: 122, loss: 0.1572\n",
      "epoch: 123, loss: 0.1580\n",
      "epoch: 124, loss: 0.1600\n",
      "epoch: 125, loss: 0.1580\n",
      "epoch: 126, loss: 0.1546\n",
      "epoch: 127, loss: 0.1513\n",
      "epoch: 128, loss: 0.1522\n",
      "epoch: 129, loss: 0.1522\n",
      "epoch: 130, loss: 0.1504\n",
      "epoch: 131, loss: 0.1508\n",
      "epoch: 132, loss: 0.1507\n",
      "epoch: 133, loss: 0.1502\n",
      "epoch: 134, loss: 0.1500\n",
      "epoch: 135, loss: 0.1550\n",
      "epoch: 136, loss: 0.1522\n",
      "epoch: 137, loss: 0.1444\n",
      "epoch: 138, loss: 0.1488\n",
      "epoch: 139, loss: 0.1445\n",
      "epoch: 140, loss: 0.1564\n",
      "epoch: 141, loss: 0.1455\n",
      "epoch: 142, loss: 0.1552\n",
      "epoch: 143, loss: 0.1510\n",
      "epoch: 144, loss: 0.1499\n",
      "epoch: 145, loss: 0.1472\n",
      "epoch: 146, loss: 0.1495\n",
      "epoch: 147, loss: 0.1449\n",
      "epoch: 148, loss: 0.1461\n",
      "epoch: 149, loss: 0.1494\n"
     ]
    }
   ],
   "source": [
    "g2g = Graph2Gauss(A=A, X=X, L=64, verbose=True, p_val=0.0, p_test=0.00, max_iter=150)\n",
    "sess = g2g.train()\n",
    "mu, sigma = sess.run([g2g.mu, g2g.sigma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro: 0.8349, f1_macro: 0.8220\n"
     ]
    }
   ],
   "source": [
    "f1_micro, f1_macro = score_node_classification(mu, z, n_repeat=1, norm=True)\n",
    "print('f1_micro: {:.4f}, f1_macro: {:.4f}'.format(f1_micro, f1_macro))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
